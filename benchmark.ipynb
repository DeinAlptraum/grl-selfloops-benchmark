{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installing dependencies and gathering datasets"
      ],
      "metadata": {
        "id": "KIKfciO1h74B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check PyTorch version installed on this system\n",
        "!python -c \"import torch; print(torch.__version__)\""
      ],
      "metadata": {
        "id": "rb2wIZQdTsDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85d1bf9-e01d-478e-f668-1e1966d7347f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Download the corresponding PyTorch Geometric module\n",
        "\"\"\"\n",
        "Assign to TORCH with what you get from the cell above. E.g., export TORCH=1.12.1+cu113\n",
        "\"\"\"\n",
        "%env TORCH=2.1.0+cu121\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "uvLG28XMUSCF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing modules, finding the GPU and importing datasets"
      ],
      "metadata": {
        "id": "Bh2SbPurluzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid, TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
        "import torch_geometric.utils as U\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"gpu\")\n",
        "\n",
        "# Cora dataset\n",
        "dsCora = Planetoid(\"/tmp/Cora\", name=\"Cora\")\n",
        "num_featuresCora = dsCora.num_node_features\n",
        "num_classesCora = dsCora.num_classes\n",
        "\n",
        "dataCora = dsCora[0].to(device)\n",
        "adj_matrixCora = U.to_dense_adj(dataCora.edge_index).squeeze(0)\n",
        "\n",
        "# NCI1 dataset\n",
        "dsNCI1 = TUDataset(\"/tmp/NCI1\", name=\"NCI1\")\n",
        "num_featuresNCI1 = dsNCI1.num_node_features\n",
        "num_classesNCI1 = dsNCI1.num_classes\n",
        "\n",
        "# 90% training data, 10% test for NCI1\n",
        "TRAIN_RATIO = 0.9\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "NCI1_train, NCI1_test = torch.utils.data.random_split(dsNCI1, [0.9,0.1])\n",
        "NCI1_train_loader = DataLoader(NCI1_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "NCI1_test_loader = DataLoader(NCI1_test, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "muJ-TbV6muhI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of basic MLP to be used at the end of every GNN layer, as defined for the $\\mathcal S,\\mathcal G$ architectures"
      ],
      "metadata": {
        "id": "D0jVmuI-u0uF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TU3I3uOMNlIe"
      },
      "outputs": [],
      "source": [
        "class MLPModule(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3, act_fn=nn.ReLU):\n",
        "      super().__init__()\n",
        "      self.act_fn = act_fn()\n",
        "      # First layer transforms from input dim to hiddem dim\n",
        "      self.layers = nn.ModuleList([nn.Linear(in_features=input_dim, out_features=hidden_dim)])\n",
        "      # All hidden layers stay in hidden_dim size for in/out\n",
        "      for _ in range(num_layers-2):\n",
        "        self.layers.append(nn.Linear(in_features=hidden_dim, out_features=hidden_dim))\n",
        "      # Last layer transforms from hidden dim to output dim\n",
        "      self.layers.append(nn.Linear(in_features=hidden_dim, out_features=output_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "      for layer in self.layers:\n",
        "        x = self.act_fn(layer(x))\n",
        "      return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of basic architecture $\\mathcal S,\\mathcal G$ layers before the MLP, i.e. with and without self-loops"
      ],
      "metadata": {
        "id": "MOXzfLBRuFJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNLayer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "      super().__init__()\n",
        "      self.self_message = nn.Linear(in_features=input_dim, out_features=output_dim)\n",
        "      self.neighbors_message = nn.Linear(in_features=input_dim, out_features=output_dim)\n",
        "\n",
        "    def forward(self, node_feats, adj_matrix):\n",
        "      self_message = self.self_message(node_feats)\n",
        "      neighbors_message = self.neighbors_message(torch.matmul(adj_matrix, node_feats))\n",
        "      return self_message + neighbors_message\n",
        "\n",
        "class GNNLayerSelfLoop(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "      super().__init__()\n",
        "      self.message = nn.Linear(in_features=input_dim, out_features=output_dim)\n",
        "\n",
        "    def forward(self, node_feats, adj_matrix):\n",
        "      message = self.message(torch.matmul(adj_matrix, node_feats))\n",
        "      return message"
      ],
      "metadata": {
        "id": "TEnA7gA9pYU3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `GNNModule` collects a bunch of GNN layers (with or without self-loops) and plugs MLPs between them."
      ],
      "metadata": {
        "id": "Rbm-Dwnfs8kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNModule(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, mlp_depth=3, self_loops=False):\n",
        "      super().__init__()\n",
        "      self.layer_type = GNNLayer\n",
        "      if self_loops:\n",
        "        self.layer_type = GNNLayerSelfLoop\n",
        "\n",
        "      self.num_layers = num_layers\n",
        "      # First layer transforms from input dim to hiddem dim\n",
        "      self.layers = nn.ModuleList([self.layer_type(input_dim, hidden_dim)])\n",
        "      # All hidden layers stay in hidden_dim size for in/out\n",
        "      for _ in range(num_layers-1):\n",
        "        self.layers.append(self.layer_type(hidden_dim, hidden_dim))\n",
        "\n",
        "      self.mlp_layers = nn.ModuleList()\n",
        "      for _ in range(num_layers-1):\n",
        "        self.mlp_layers.append(MLPModule(hidden_dim, hidden_dim, hidden_dim, mlp_depth))\n",
        "      # Last MLP transforms from hidden dim to output dim\n",
        "      self.mlp_layers.append(MLPModule(hidden_dim, hidden_dim, output_dim, mlp_depth))\n",
        "\n",
        "    def forward(self, x, adj_matrix):\n",
        "      for l in range(self.num_layers):\n",
        "        x = self.mlp_layers[l](self.layers[l](x, adj_matrix))\n",
        "      return x"
      ],
      "metadata": {
        "id": "kRzeNjIWXLpD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the models for Cora node classification and NCI1 graph classification, including evaluation and training functions"
      ],
      "metadata": {
        "id": "B3sUDyK6wUMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "class CoraNodeClassification(nn.Module):\n",
        "    def __init__(self, num_features: int, hidden_features: int, num_classes: int, num_gnn_layers: int, num_mlp_layers: int, self_loops: bool):\n",
        "      super().__init__()\n",
        "      self.self_loops = self_loops\n",
        "      self.gnn = GNNModule(num_features, hidden_features, num_classes, num_gnn_layers, num_mlp_layers, self_loops)\n",
        "      pass\n",
        "\n",
        "    def forward(self, data, adj_matrix):\n",
        "      return self.gnn(data, adj_matrix)\n",
        "\n",
        "    def test_on(self, data, adj_matrix):\n",
        "        self.eval()\n",
        "        res = self(data.x, adj_matrix)\n",
        "        res_evaluated = torch.argmax(res, dim=1)\n",
        "        masked_truth = data.y[data.test_mask]\n",
        "        masked_res = res_evaluated[data.test_mask]\n",
        "        return (masked_truth==masked_res).sum().item()/masked_truth.shape[0]\n",
        "\n",
        "    def train_on(self, data, adj_matrix, learning_rate: float, num_epochs: int):\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
        "      for i in range(num_epochs):\n",
        "        self.train()\n",
        "        optimizer.zero_grad()\n",
        "        y = self(data.x, adj_matrix)\n",
        "        loss = loss_fn(y[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "cNVsovJTYk7X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NCI1GraphClassification(nn.Module):\n",
        "    def __init__(self, num_features: int, hidden_features: int, num_classes: int, num_gnn_layers: int, num_mlp_layers: int, self_loops: bool, pool_max: bool = True):\n",
        "      super().__init__()\n",
        "      self.self_loops = self_loops\n",
        "      self.pool_max = pool_max\n",
        "      self.gnn = GNNModule(num_features, hidden_features, num_classes, num_gnn_layers, num_mlp_layers, self_loops)\n",
        "      pass\n",
        "\n",
        "    def forward(self, data, adj_matrix):\n",
        "      return self.gnn(data, adj_matrix)\n",
        "\n",
        "    def _evaluate_one_batch(self, data):\n",
        "        adj_matrix = U.to_dense_adj(data.edge_index).squeeze(0)\n",
        "        batch_res = self(data.x, adj_matrix)\n",
        "        if self.pool_max:\n",
        "          preds = global_max_pool(batch_res, data.batch)\n",
        "        else:\n",
        "          preds = global_mean_pool(batch_res, data.batch)\n",
        "        return preds\n",
        "\n",
        "    def test_on(self, loader):\n",
        "        self.eval()\n",
        "        hits = 0\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            preds = self._evaluate_one_batch(data)\n",
        "            preds = preds.argmax(dim=1)\n",
        "            hits += preds.eq(data.y).sum().item()\n",
        "        return hits/len(loader.dataset)\n",
        "\n",
        "    def train_on(self, loader, learning_rate: float, num_epochs: int):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
        "        for i in range(num_epochs):\n",
        "          self.train()\n",
        "          for data in loader:\n",
        "            optimizer.zero_grad()\n",
        "            data = data.to(device)\n",
        "            preds = self._evaluate_one_batch(data)\n",
        "            loss = loss_fn(preds, data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n"
      ],
      "metadata": {
        "id": "j1GIkWnZK_47"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the basic benchmark functions, base parameters and run all test cases for parameter combinations."
      ],
      "metadata": {
        "id": "jfeXY4_koR86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def average_model(params, modelType: nn.Module, data, adj_matrix, num_runs=10):\n",
        "  accs = []\n",
        "  for i in range(num_runs):\n",
        "    if modelType is CoraNodeClassification:\n",
        "      model = modelType(params[\"num_features\"],\n",
        "                  params[\"hidden_features\"],\n",
        "                  params[\"num_classes\"],\n",
        "                  params[\"num_gnn_layers\"],\n",
        "                  params[\"num_mlp_layers\"],\n",
        "                  params[\"self_loops\"],\n",
        "      ).to(device)\n",
        "      model.train_on(dataCora, adj_matrixCora, params[\"learning_rate\"], params[\"num_epochs\"])\n",
        "      accs.append(model.test_on(dataCora, adj_matrixCora))\n",
        "    elif modelType is NCI1GraphClassification:\n",
        "      model = modelType(params[\"num_features\"],\n",
        "                        params[\"hidden_features\"],\n",
        "                        params[\"num_classes\"],\n",
        "                        params[\"num_gnn_layers\"],\n",
        "                        params[\"num_mlp_layers\"],\n",
        "                        params[\"self_loops\"],\n",
        "                        params[\"pool_max\"],\n",
        "      ).to(device)\n",
        "      model.train_on(NCI1_train_loader, params[\"learning_rate\"], params[\"num_epochs\"])\n",
        "      accs.append(model.test_on(NCI1_test_loader))\n",
        "  accuracy = sum(accs)/num_runs\n",
        "  return accuracy\n",
        "\n",
        "def benchmark(param_key: str, values: list):\n",
        "  base_paramsCora = {\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"num_epochs\": 256,\n",
        "    \"num_features\": num_featuresCora,\n",
        "    \"num_classes\": num_classesCora,\n",
        "    \"self_loops\": False,\n",
        "    \"hidden_features\": 64,\n",
        "    \"num_gnn_layers\": 3,\n",
        "    \"num_mlp_layers\": 3,\n",
        "  }\n",
        "  base_paramsNCI1 = {\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"num_epochs\": 32,\n",
        "    \"num_features\": num_featuresNCI1,\n",
        "    \"num_classes\": num_classesNCI1,\n",
        "    \"self_loops\": False,\n",
        "    \"hidden_features\": 64,\n",
        "    \"num_gnn_layers\": 3,\n",
        "    \"num_mlp_layers\": 3,\n",
        "    \"pool_max\": False,\n",
        "  }\n",
        "  paramsCora = dict(base_paramsCora)\n",
        "  paramsNCI1 = dict(base_paramsNCI1)\n",
        "\n",
        "  accsCora = ([],[])\n",
        "  accsNCI1 = ([],[])\n",
        "  for self_loops in [False, True]:\n",
        "    paramsCora[\"self_loops\"] = self_loops\n",
        "    paramsNCI1[\"self_loops\"] = self_loops\n",
        "    for val in values:\n",
        "      paramsCora[param_key] = val\n",
        "      paramsNCI1[param_key] = val\n",
        "      if \"param_key\" != \"pool_max\":\n",
        "        accCora = average_model(paramsCora, CoraNodeClassification, dataCora, adj_matrixCora, 10)\n",
        "        accsCora[self_loops].append(accCora)\n",
        "      accNCI1 = average_model(paramsNCI1, NCI1GraphClassification, dataCora, adj_matrixCora, 10)\n",
        "      accsNCI1[self_loops].append(accNCI1)\n",
        "  print(f\"Accuracy for {param_key} in {values}\")\n",
        "  if \"param_key\" != \"pool_max\":\n",
        "    print(\"Cora without self-loops: \", accsCora[False])\n",
        "    print(\"Cora with self-loops: \", accsCora[True])\n",
        "  print(\"NCI1 without self-loops: \", accsNCI1[False])\n",
        "  print(\"NCI1 with self-loops: \", accsNCI1[True])\n",
        "\n",
        "benchmark(\"num_gnn_layers\", [1,2,3,4,5])\n",
        "benchmark(\"num_mlp_layers\", [1,2,3,4,5])\n",
        "benchmark(\"hidden_features\", [16,32,64,128,256])\n",
        "benchmark(\"pool_max\", [False,True])\n"
      ],
      "metadata": {
        "id": "ycmyiU4VYOqU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}